# fly.toml - TailorBlend AI Consultant Backend API
# Deployment configuration for fly.io

app = "tailorblend-backend-api"
primary_region = "jnb"  # Johannesburg, South Africa

[build]
  dockerfile = "Dockerfile"

[env]
  ASPNETCORE_ENVIRONMENT = "Production"
  PYTHON_API_PORT = "8080"  # fly.io uses 8080 as standard port

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = "off"
  auto_start_machines = true
  min_machines_running = 1

  # HTTP options for SSE streaming support
  [http_service.http_options]
    response.read_timeout = "5m"  # Allow long-running SSE streams
    h2_backend = false  # Force HTTP/1.1 for better SSE compatibility

  [http_service.concurrency]
    type = "connections"
    hard_limit = 250
    soft_limit = 200

  # Health check with increased tolerances for slow startup
  [[http_service.checks]]
    grace_period = "180s"  # Increased from 60s to allow OpenAI SDK initialization
    interval = "30s"
    method = "GET"
    timeout = "10s"  # Increased from 5s for more tolerance
    path = "/api/health"

# VM configuration - Optimized for cost (cheapest always-on option)
# shared-cpu-1x with 256MB = $2.02/month (was $3.32 with 512MB)
# Suitable for low-traffic personal/testing use
# If you experience OOM errors, upgrade to 512MB
[vm]
  size = "shared-cpu-1x"
  memory = "256mb"

# Swap provides emergency buffer if 256MB RAM is insufficient
# This prevents crashes during memory spikes (e.g., OpenAI SDK initialization)
swap_size_mb = 512

# Environment variables for production
# CORS_ALLOWED_ORIGINS should be set via fly secrets:
#   fly secrets set CORS_ALLOWED_ORIGINS="https://tailorblend-frontend-ui.fly.dev"
