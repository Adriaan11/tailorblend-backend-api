# fly.toml - TailorBlend AI Consultant Backend API
# Deployment configuration for fly.io

app = "tailorblend-backend-api"
primary_region = "jnb"  # Johannesburg, South Africa

[build]
  dockerfile = "Dockerfile"

[env]
  ASPNETCORE_ENVIRONMENT = "Production"
  PYTHON_API_PORT = "8080"  # fly.io uses 8080 as standard port

[http_service]
  internal_port = 8080
  force_https = true
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 0

  # HTTP options for SSE streaming support
  [http_service.http_options]
    response.read_timeout = "5m"  # Allow long-running SSE streams
    h2_backend = false  # Force HTTP/1.1 for better SSE compatibility

  [http_service.concurrency]
    type = "connections"
    hard_limit = 250
    soft_limit = 200

  # Health check with increased tolerances for slow startup
  [[http_service.checks]]
    grace_period = "180s"  # Increased from 60s to allow OpenAI SDK initialization
    interval = "30s"
    method = "GET"
    timeout = "10s"  # Increased from 5s for more tolerance
    path = "/api/health"

# VM configuration - Minimum 512MB required for OpenAI Agents SDK
# shared-cpu-1x with 512MB = $3.32/month
# DO NOT reduce to 256MB - causes OOM kills during chat requests
[vm]
  size = "shared-cpu-1x"
  memory = "512mb"

# Swap provides additional buffer for memory spikes
# Helps prevent OOM during concurrent requests or large contexts
swap_size_mb = 512

# Environment variables for production
# CORS_ALLOWED_ORIGINS should be set via fly secrets:
#   fly secrets set CORS_ALLOWED_ORIGINS="https://tailorblend-frontend-ui.fly.dev"
